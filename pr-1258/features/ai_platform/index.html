
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>AI Platform &#8212; S-CORE 0.1 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/score.css?v=940e959b" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/score_needs.css?v=e97392eb" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/score_design.css?v=d9fd870c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-data-viewer/jsonview.bundle.css?v=f6ef2277" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-needs/libs/html/datatables.min.css?v=4b4fd840" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-needs/common_css/need_links.css?v=2150a916" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-needs/common_css/need_toggle.css?v=5c6620df" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-needs/common_css/needstable.css?v=5e1b6797" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-needs/common_css/need_core.css?v=f5b60a78" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-needs/common_css/need_style.css?v=92936fa5" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-needs/modern.css?v=803738c0" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/jquery.js?v=5d32c60e"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script src="../../_static/documentation_options.js?v=2709fde1"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../_static/sphinx-data-viewer/jsonview.bundle.js?v=18cd53c5"></script>
    <script src="../../_static/sphinx-data-viewer/jsonview_loader.js?v=f7ff7e7d"></script>
    <script src="../../_static/sphinx-needs/libs/html/datatables.min.js?v=8a4aee21"></script>
    <script src="../../_static/sphinx-needs/libs/html/datatables_loader.js?v=a2cae175"></script>
    <script src="../../_static/sphinx-needs/libs/html/sphinx_needs_collapse.js?v=dca66431"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'features/ai_platform/index';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Requirements" href="requirements/index.html" />
    <link rel="prev" title="Features" href="../index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="0.1" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Eclipse S-CORE</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../introduction/index.html">
    Introduction
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../requirements/index.html">
    Requirements
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Features
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contribute/index.html">
    Contribute
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../score_releases/index.html">
    Releases
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button"
                data-bs-toggle="dropdown" aria-expanded="false"
                aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../platform_management_plan/index.html">
    PMP
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-external" href="https://projects.eclipse.org/projects/automotive.score">
    Eclipse
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/eclipse-score" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../introduction/index.html">
    Introduction
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../requirements/index.html">
    Requirements
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Features
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contribute/index.html">
    Contribute
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../score_releases/index.html">
    Releases
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../platform_management_plan/index.html">
    PMP
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://projects.eclipse.org/projects/automotive.score">
    Eclipse
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/eclipse-score" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="current reference internal" href="#">AI Platform</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="requirements/index.html">Requirements</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../analysis-infra/index.html">Analysis Infrastructure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../communication/index.html">Communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../frameworks/index.html">Frameworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infrastructure/index.html">Infrastructure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../integration/index.html">Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../persistency/index.html">Persistency</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">Features</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">AI Platform</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="ai-platform">
<span id="ai-platform-feature"></span><h1>AI Platform<a class="headerlink" href="#ai-platform" title="Link to this heading">#</a></h1>
<div class="need_container docutils container" id="SNCB-c4cc67b1">
<div class="pst-scrollable-table-container"><table class="need needs_grid_complex needs_layout_score needs_style_none needs_type_document table" id="doc__ai_platform">
<tbody>
<tr class="head row-odd"><td class="head_left" colspan="2"><div class="needs_head_left line-block">
<div class="line"><span><span class="needs_title"><span class="needs_data">AI-Platform</span></span></span></div>
</div>
</td>
<td class="head_center" colspan="2"><div class="needs_head line-block">
<div class="line"><span><span class="needs_status"><span class="needs_label">status: </span><span class="needs_data">draft</span></span></span></div>
<div class="line"><span></span></div>
<div class="line"><span><span class="needs_safety"><span class="needs_label">safety: </span><span class="needs_data">ASIL_B</span></span></span></div>
</div>
</td>
<td class="head_right" colspan="2"><div class="needs_head_right line-block">
<div class="line"><span><span class="needs needs_collapse" id="target__show__meta"><span class="needs collapsed"><svg xmlns="http://www.w3.org/2000/svg" width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-down-circle"><circle cx="12" cy="12" r="10"></circle><polyline points="8 12 12 16 16 12"></polyline><line x1="12" y1="8" x2="12" y2="16"></line></svg></span><span class="needs visible collapse_is_hidden"><svg xmlns="http://www.w3.org/2000/svg" width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right-circle"><circle cx="12" cy="12" r="10"></circle><polyline points="12 16 16 12 12 8"></polyline><line x1="8" y1="12" x2="16" y2="12"></line></svg></span></span></span></div>
</div>
</td>
</tr>
<tr class="meta row-even"><td class="meta" colspan="3"><div class="needs_meta_left line-block">
<div class="line"><span><span><div class="line"><span class="needs_status"><span class="needs_label">status: </span><span class="needs_data">draft</span></span></div>
<div class="line"><span class="needs_tags"><span class="needs_label">tags: </span><span class="needs_data_container"><span class="needs_data">feature_request</span></span></span></div>
<div class="line"><span class="needs_safety"><span class="needs_label">safety: </span><span class="needs_data">ASIL_B</span></span></div>
</span></span></div>
<div class="line"><span></span></div>
</div>
</td>
<td class="meta" colspan="3"></td>
</tr>
<tr class="content row-odd"><td class="content" colspan="6"></td>
</tr>
<tr class="footer row-even"><td class="footer_left" colspan="2"><div class="needs_footer_left line-block">
<div class="line"><span><span class="needs-id"><a class="reference internal" href="#doc__ai_platform" title="doc__ai_platform">doc__ai_platform</a></span></span></div>
</div>
</td>
<td class="footer" colspan="2"><div class="needs_footer line-block">
<div class="line"><span><span class="needs_type_name"><span class="needs_data">Generic Document</span></span></span></div>
</div>
</td>
<td class="footer_right" colspan="2"></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="toctree-wrapper compound">
</div>
<section id="feature-flag">
<h2>Feature flag<a class="headerlink" href="#feature-flag" title="Link to this heading">#</a></h2>
<p>To activate this feature, use the following feature flag:</p>
<p><code class="docutils literal notranslate"><span class="pre">experimental_ai_platform</span></code></p>
</section>
<section id="abstract">
<h2>Abstract<a class="headerlink" href="#abstract" title="Link to this heading">#</a></h2>
<p>This feature request outlines the foundational requirements for integrating AI workloads into the S-CORE automotive platform,
with a particular emphasis on enabling inference capabilities across both QNX and Linux operating systems.
The primary goal is to provide support for ASIL-B compliant use cases on QNX through a thin,
vendor-agnostic abstraction layer for AI backends such as TensorRT or QNN.
For non-safety-critical applications, a standardized inference backend—such as ONNX Runtime—should be supported,
despite its current lack of compatibility with QNX.
Generative AI (GenAI) workloads are a core part of the platform scope on Linux,
enabling on-device LLM inference for intelligent in-vehicle interactions.</p>
<p>The document proposes extending S-CORE components (e.g., FEO, Communication, Error Handling)
to support AI models natively, avoiding duplicate logic across software domains.
Furthermore, it introduces a scoped investigation into GPU shared memory (SHM) and
data pipelining mechanisms to abstract communication of GPU-resident objects.</p>
</section>
<section id="motivation">
<h2>Motivation<a class="headerlink" href="#motivation" title="Link to this heading">#</a></h2>
<p>The AI Platform is needed to support the industry’s transition from traditional rule-based systems and fixed-function ECUs to
software-defined and increasingly AI-defined vehicles.
As automotive platforms evolve, intelligent systems must be able to process perception, planning and driver interaction using machine-learned behavior.
The AI Platform enables modular, safety-aligned integration of ML and GenAI components
and provides the foundation for moving from a Software-Defined Vehicle (SDV) architecture to an AI-Defined Vehicle (AIDV).</p>
</section>
<section id="rationale">
<h2>Rationale<a class="headerlink" href="#rationale" title="Link to this heading">#</a></h2>
<p>This approach in this Feature Request was selected to ensure a modular, certifiable, and platform-agnostic AI integration layer for automotive applications.
By abstracting inference backends and structuring data flow through standardized interfaces, the architecture enables safety certification (ASIL-B),
supports reuse across Linux and QNX, and allows for flexibility in deploying both ML and GenAI models.
It balances the need for runtime efficiency, safety alignment, and support for future AI-defined vehicle concepts.</p>
</section>
<section id="specification">
<h2>Specification<a class="headerlink" href="#specification" title="Link to this heading">#</a></h2>
<p>This feature request aims to extend the S-CORE platform to support AI workloads across both QNX and Linux environments,
enabling safe and efficient execution of models for both safety-critical and non-critical automotive functions.
The architectural concept focuses on a modular inference pipeline, supporting a unified abstraction for AI model execution,
backend integration, and GPU-based communication.</p>
<section id="operating-system-support-and-asil-alignment">
<h3>Operating System Support and ASIL Alignment<a class="headerlink" href="#operating-system-support-and-asil-alignment" title="Link to this heading">#</a></h3>
<p>The platform must support both Linux and QNX, with differing priorities and use-case profiles.
QNX is prioritized (Priority 1) due to its relevance in safety applications.
Linux support (Priority 2) primarily targets non-safety-critical applications, including Generative AI (GenAI) workloads.
Safety use cases will adhere to the constraints imposed by functional safety requirements,
whereas Linux allows for more flexible development.
All features available on QNX will also be available on Linux.</p>
<section id="qnx">
<h4>QNX<a class="headerlink" href="#qnx" title="Link to this heading">#</a></h4>
<p>The figure below shows the high level scope for the QNX platform with a target of ASIL-B.
The two main components are the <strong>Vendor Abstraction</strong> (Backend Adapter) and the <strong>Data Pipeline</strong>.</p>
<img alt="AI Platform Architecture Overview QNX" src="../../_images/score-aip-qnx.drawio.svg" />
</section>
<section id="linux">
<h4>Linux<a class="headerlink" href="#linux" title="Link to this heading">#</a></h4>
<p>The next figure shows the scope of the Linux-based platform.
All components running on QNX shall also run on Linux - but not the other way around.
In addition to the QNX scope, GenAI related components like <strong>MCP Server</strong> a <strong>Context API</strong> included.</p>
<img alt="AI Platform Architecture Overview Linux" src="../../_images/score-aip-linux.drawio.svg" />
</section>
</section>
<section id="inference-backend-integration-and-abstraction-layer">
<h3>Inference Backend Integration and Abstraction Layer<a class="headerlink" href="#inference-backend-integration-and-abstraction-layer" title="Link to this heading">#</a></h3>
<p>The idea of this component is to provide a lightweight and certifiable abstraction layer that decouples applications from vendor specific APIs.</p>
<p>To provide model execution capability, the system must support inference backends via a thin abstraction layer.
This layer will expose a unified interface to the upper layers of the stack while delegating execution to optimized
vendor runtimes underneath — such as TensorRT for NVIDIA, or QNN for Qualcomm-based systems.
For non-safety use cases, a standardized backend like ONNX Runtime <a class="footnote-reference brackets" href="#s1" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> should be supported to ensure portability and developer accessibility.
However, ONNX Runtime currently lacks QNX support - which will further be investigated.</p>
<section id="concept">
<h4>Concept<a class="headerlink" href="#concept" title="Link to this heading">#</a></h4>
<p>The diagram below illustrates the architecture of the AIP Abstraction Layer - here called ModelAPI.
It highlights how a unified Adapter Interface allows seamless integration with different hardware-dependent inference backends
(e.g. ONNX Runtime, TensorRT), as well as a mock backend for testing.
The IOUtils module handles preprocessing and input preparation.
Keeping IOUtils as a separate library helps isolate input handling logic from inference logic,
making it easier to test, reuse, and extend preprocessing across different models and backends.
This structure allows isolating and certifying components independently, which is essential for scalable safety certification.</p>
<p class="plantuml">
<object data="../../_images/plantuml-2b94abb6fff0cbcb7d94eaa18e8c3580811dc840.svg" type="image/svg+xml" style="width:815px;height:520px;background:#FFFFFF;"></object></p>
<p>Key benefits of this concept include:</p>
<ul class="simple">
<li><p>Static backend selection at compile time ensures deterministic behavior and reduces runtime complexity</p></li>
<li><p>Clear separation of responsibilities (e.g., IOUtils vs inference adapters) supports modular safety analysis</p></li>
<li><p>MockAdapter enables early testing and CI validation without requiring hardware targets</p></li>
<li><p>Minimal and auditable abstractions make the system easier to verify and validate, especially when wrapping certified inference engines (when used as a Safety Element out of Context, SEooC)</p></li>
</ul>
</section>
<section id="adapter-class">
<h4>Adapter Class<a class="headerlink" href="#adapter-class" title="Link to this heading">#</a></h4>
<p>The class diagram below shows the object-oriented structure of the Adapter system.
All backend adapters inherit from a shared abstract interface, ensuring consistent model loading and inference APIs across implementations.
One of the main challenges of this approach is to find the common set of features between all backend APIs to be abstracted.
Finding the right balance between abstraction and feature set may be challenging.</p>
<p class="plantuml">
<object data="../../_images/plantuml-45186397932e2fad442957b5ef78bfe5f7334251.svg" type="image/svg+xml" style="width:681px;height:235px;background:#FFFFFF;"></object></p>
</section>
<section id="backend-selection-mechanism">
<h4>Backend Selection Mechanism<a class="headerlink" href="#backend-selection-mechanism" title="Link to this heading">#</a></h4>
<p>The following diagram shows how the backend implementation is selected at compile time via CMake flags.
Depending on the configuration, either the ONNX Runtime, TensorRT, or a mock adapter is compiled into the application.
The static backend selection at compile time ensures deterministic behavior and reduces runtime complexity which simplifies certification.</p>
<p class="plantuml">
<object data="../../_images/plantuml-8395172fb0103cdb0f5eb21f1dfffa2e6197bd32.svg" type="image/svg+xml" style="width:579px;height:259px;background:#FFFFFF;"></object></p>
</section>
</section>
<section id="data-pipelining-and-gpu-communication-abstraction">
<h3>Data Pipelining and GPU Communication Abstraction<a class="headerlink" href="#data-pipelining-and-gpu-communication-abstraction" title="Link to this heading">#</a></h3>
<p>Many models — especially vision-based ones — depend on high-throughput data exchange in GPU memory.
To support efficient data flow, the architecture should provide a data pipelining layer that abstracts objects in the GPU memory space.</p>
<p>This may include:</p>
<ul class="simple">
<li><p>Shared memory buffers between producer (e.g. camera driver) and consumer (e.g. model preprocessing)</p></li>
<li><p>Zero-copy mechanisms to minimize CPU-GPU transfers and reduce latency</p></li>
<li><p>Standardized data contracts for tensor formats and metadata</p></li>
</ul>
<p>A key challenge here is observability: current S-CORE recording may not capture GPU-to-GPU data flows.
A second challenge is the tight coupling of GPU memory object to vendor specific libraries.
Therefore, the exact scope and feasibilty of this component and its respective gaps must be investigated in-depth by a future feature request.</p>
<p>The figure below shows the high level concept of a data pipeline and backend adapter.</p>
<img alt="AI Platform Abstraction" src="../../_images/score-aip-abstraction.drawio.svg" />
</section>
<section id="s-core-integration-feo-communication-and-fault-management">
<h3>S-CORE Integration: FEO, Communication, and Fault Management<a class="headerlink" href="#s-core-integration-feo-communication-and-fault-management" title="Link to this heading">#</a></h3>
<p>AI model execution should be integrated into existing S-CORE components — not implemented as a standalone subsystem.</p>
<p>This includes:</p>
<ul class="simple">
<li><p>FEO: Integration allows AI tasks to be scheduled and monitored like any other activity</p></li>
<li><p>Communication: Model inputs and outputs must seamlessly fit into the existing communication model</p></li>
<li><p>Error Handling: Faults and anomalies during inference (e.g., invalid input tensors, timeout, memory access issues) must be reported and handled using S-CORE’s diagnostic framework</p></li>
<li><p>Recording: Data between AI/ML nodes with GPU memory object should be recordable in the same manner as regular IPC communication</p></li>
</ul>
<p>This unified approach avoids fragmentation and ensures that AI models are treated as first-class citizens within the system.</p>
</section>
<section id="genai">
<h3>GenAI<a class="headerlink" href="#genai" title="Link to this heading">#</a></h3>
<p>This section defines the platform’s support for Generative AI (GenAI), with a focus on enabling on-device inference
using small and large language models (SLM/LLMs) for interactions in the vehicle context.</p>
<p>In addition to standard prompt-response interaction, the scope includes support for agentic capabilities — enabling
LLM-based agents that operate with situational awareness, memory, goal orientation, and structured communication with vehicle systems.</p>
<section id="scope-overview">
<h4>Scope Overview<a class="headerlink" href="#scope-overview" title="Link to this heading">#</a></h4>
<p>The platform shall support Generative AI inference on Linux targets for non-safety-critical use cases,
enabling contextual in-vehicle assistance and edge-based small and large language model (SLM/LLM) execution.
The focus is on enabling model execution, streamlined integration with in-vehicle communication systems and flexible data injection via APIs.</p>
<p><em>Note: SLM/LLMs need function calling capability for the whole scope of this proposal to be accessible.</em></p>
<p>Key Goals:</p>
<ul class="simple">
<li><p>Enable on-device SLM/LLM inference using runtimes such as llama.cpp</p></li>
<li><p>Support inference on multiple models at the same time</p></li>
<li><p>Define a Context API that allows the injection of relevant task context, session memory, driver preferences, and environmental factors into the LLM</p></li>
<li><p>Provide an MCP Server that exposes vehicle states and control interfaces to the SLM/LLM in a structured, machine-readable format, enabling real-time interaction with in-vehicle systems</p></li>
</ul>
<p>The table below gives a brief overview of considered components and their respective function.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Component</strong></p></th>
<th class="head"><p><strong>Description</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Runtime</p></td>
<td><p>Runtime support for lightweight LLMs (e.g. llama.cpp)</p></td>
</tr>
<tr class="row-odd"><td><p>Prompting Interface</p></td>
<td><p>Manages prompt templates, roles, chaining, and streaming I/O</p></td>
</tr>
<tr class="row-even"><td><p>Context API</p></td>
<td><p>Interface to manage agent memory, goals, session</p></td>
</tr>
<tr class="row-odd"><td><p>MCP Server</p></td>
<td><p>Provides structured vehicle context and tools</p></td>
</tr>
<tr class="row-even"><td><p>Action Validator</p></td>
<td><p>Safety layer to validate LLM-generated actions before execution</p></td>
</tr>
</tbody>
</table>
</div>
<p>The figure below outlines the core data and control flow connections between components in the GenAI Subsystem.</p>
<img alt="AI Platform GenAI Subsystem" src="../../_images/score-aip-genai.drawio.svg" />
<p>Basic data/control flow explanation:</p>
<ul class="simple">
<li><p>The Prompting Interface sends a fully constructed prompt — containing system messages, user input, and injected context — to the LLM for inference. This serves as the main entry point for user interaction and model execution.</p></li>
<li><p>The Prompting Interface also monitors the token stream returned by the LLM, buffering output for speech or display and detecting structured outputs such as function calls or action proposals. When an action is detected, it is passed to the Action Validator for policy enforcement.</p></li>
<li><p>The Prompting Interface retrieves relevant context from the Context API. This includes session memory, task goals, and personalization data that shape how prompts are built and responses are interpreted. In addition, it queries live vehicle state and resource availability via the MCP Client.</p></li>
<li><p>The Context API manages user preferences, goals, and session memory.</p></li>
<li><p>The MCP Server acts as a proxy between the GenAI subsystem and the vehicle platform. It reads sensor and state data from the Vehicle API and exposes tools (i.e., callable functions) for executing commands like HVAC control.</p></li>
<li><p>When the Action Validator approves a proposed action, the MCP Server sends the command to the Vehicle API for execution by the vehicle systems.</p></li>
</ul>
</section>
<section id="runtime">
<h4>Runtime<a class="headerlink" href="#runtime" title="Link to this heading">#</a></h4>
<p>The platform shall support model runtimes like llama.cpp <a class="footnote-reference brackets" href="#s2" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a> for model execution.
It is <strong>not</strong> a goal to provide a proprietary runtime.</p>
</section>
<section id="prompting-interface">
<h4>Prompting Interface<a class="headerlink" href="#prompting-interface" title="Link to this heading">#</a></h4>
<p>The Prompting Interface is the central orchestration layer that governs how LLMs receive inputs, structure responses, and interact with other system components.
While the underlying runtime performs raw text generation one token at a time, the Prompting Interface manages everything around it —
ensuring that prompts are context-aware, structured, and suitable for interactive, real-time use.
Additionally, it is hosted in the same process as the MCP Client which allows it to retrieve context and tools from a domain like the vehicle.</p>
<p>The prompting interface includes following features:</p>
<ul class="simple">
<li><dl class="simple">
<dt>Prompt Templating</dt><dd><ul>
<li><p>Supports distinct roles (system, user) and injects them as structured tokens</p></li>
<li><p>The roles enable a differentiation between user and non-user interactions</p></li>
<li><p>Ensures prompts are predictable, reusable, and structured across tasks</p></li>
<li><p>Encourages consistent tone and framing</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Dynamic Context Injection</dt><dd><ul>
<li><p>Pulls real-time and personalized data from other sources (e.g., MCP server, Context API)</p></li>
<li><p>Injects variables such as <code class="docutils literal notranslate"><span class="pre">current_speed</span></code>, <code class="docutils literal notranslate"><span class="pre">destination</span></code>, <code class="docutils literal notranslate"><span class="pre">driver_name</span></code>, <code class="docutils literal notranslate"><span class="pre">external_temperature</span></code></p></li>
<li><p>Allows LLMs to tailor responses based on driving situation, weather, or personal preferences</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Prompt Chaining</dt><dd><ul>
<li><p>Splits complex queries or tasks into smaller subtasks and manages their sequencing</p></li>
<li><p>Useful for multi-turn workflows (e.g. POI search + voice confirmation)</p></li>
<li><p>May involve internal reasoning steps that remain hidden from the user</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Streaming Output Decoding</dt><dd><ul>
<li><p>Handles incremental output from the model, token by token</p></li>
<li><p>Enables responsive voice assistants and progressive rendering of long responses</p></li>
<li><p>Manages buffering, line completion, and fallback behavior (e.g. timeouts, retries)</p></li>
<li><p>Passes actions to MCP Client for invokation</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>Together, these features elevate the SLM/LLM from a raw text generator to a well-structured, interactive agent.
The Prompting Interface is essential for ensuring that GenAI systems behave predictably, contextually, and safely in embedded, real-time environments.</p>
</section>
<section id="context-api">
<h4>Context API<a class="headerlink" href="#context-api" title="Link to this heading">#</a></h4>
<p>The Context API is a conceptual interface for managing task-level memory, dialogue state, and user preferences during LLM-based interactions.
It provides structured access to:</p>
<ul class="simple">
<li><p>Short-term context: Current goal, location, dialogue state</p></li>
<li><p>Long-term context: Driver preferences, history, personalization</p></li>
</ul>
<p>This modular separation allows LLMs/agents to reason over abstract context without being tightly coupled to hardware interfaces.
This modular separation allows LLMs and agents to reason over abstract context — such as goals, preferences, and session state —
without direct coupling to low-level system interfaces like the file system or persistent storage.</p>
<p>The Context API will also allow updates to long-term user context.</p>
</section>
<section id="model-context-protocol-mcp-client-server">
<h4>Model Context Protocol (MCP) Client/Server<a class="headerlink" href="#model-context-protocol-mcp-client-server" title="Link to this heading">#</a></h4>
<p>MCP <a class="footnote-reference brackets" href="#s3" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a> provides structured data to the LLM in a machine-readable format. For example:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">vehicle.speed</span></code>: Current vehicle speed</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nav.destination</span></code>: Active navigation goal</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">climate.status</span></code>: A/C on/off, temperature</p></li>
</ul>
<p>It also maps safe commands that may be executed. For example:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;action&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;set_temperature&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;zone&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;driver&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">22</span><span class="w"> </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>This ensures LLM/agent outputs can be transformed into machine-executable commands through explicit contracts.</p>
<p>Due to the MCP specification enforcing a 1:1 client-server connection, the MCP Client is hosted within the Main Application.
This architectural choice ensures that only a single authoritative interface manages communication with the MCP Server.
Consequently, the Context API does not interface with the MCP Server directly.
Instead, the Prompting Interface (PI) retrieves live vehicle context data via the MCP Client,
combining it with internal session and user state managed by the Context API.</p>
</section>
<section id="action-validator">
<h4>Action Validator<a class="headerlink" href="#action-validator" title="Link to this heading">#</a></h4>
<p>To ensure safety and traceability, all GenAI-generated commands should be validated by an Action Validator before being executed.
This component should be designed as an abstract base class and extended for the final use case by the user.</p>
<p>Implementations examples include:</p>
<ul class="simple">
<li><p>Rule-based filters (e.g. prohibit certain actions at high speed)</p></li>
<li><p>Context-aware rejection (e.g. don’t open windows in rain)</p></li>
</ul>
<p>This mechanism ensures that LLMs remain advisory and non-authoritative in mixed-criticality systems.
Upon approval by the Action Validator, the MCP Server executes the command of the respective MCP tool.</p>
<p>Advantages of using the Action Validator in the MCP Server (rather than in the Prompting Interface) include:</p>
<ul class="simple">
<li><p>Action validation is close to the domain and can follow same domain specific non-functional requirements</p></li>
<li><p>MCP Server already has access to state data which simplifies rule checking</p></li>
<li><p>Easy to extend for new or existing MCP tools - only one component is affected by change</p></li>
</ul>
</section>
</section>
<section id="requirements">
<h3>Requirements<a class="headerlink" href="#requirements" title="Link to this heading">#</a></h3>
<p>The related requirements can be found in <a class="reference internal" href="requirements/index.html"><span class="doc">Requirements</span></a>.</p>
</section>
</section>
<section id="backwards-compatibility">
<h2>Backwards Compatibility<a class="headerlink" href="#backwards-compatibility" title="Link to this heading">#</a></h2>
<p>Backwards compatibility to current systems is ensured by supporting established frameworks and only providing light weight abstractions and support-components around it.</p>
</section>
<section id="security-impact">
<h2>Security Impact<a class="headerlink" href="#security-impact" title="Link to this heading">#</a></h2>
<p>The AI Platform introduces several new attack surfaces that require security consideration across both inference and GenAI subsystems.
Therefore, the overall security architecture must be revisited in detail to assess and mitigate potential risks.</p>
<p>The following non-complete list highlights a few security considerations per component.</p>
<ul class="simple">
<li><dl class="simple">
<dt>Inference Backends</dt><dd><ul>
<li><p>Ensure that model binaries are verified, authenticated, and integrity-checked before execution</p></li>
<li><p>Restrict model file loading to trusted paths and signed artifacts to prevent tampering or malicious injection</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>GenAI (LLM) Execution</dt><dd><ul>
<li><p>Prompt inputs must be validated and rate-limited to protect against injection attacks or malformed sequences</p></li>
<li><p>The action validator must enforce whitelisting of executable commands to prevent unsafe or unintended vehicle operations</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>MCP and Context APIs</dt><dd><ul>
<li><p>All communication with the MCP Server must be authenticated and authorized</p></li>
<li><p>Write operations to the Context API (e.g. preference updates) must be explicitly scoped and validated</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="safety-impact">
<h2>Safety Impact<a class="headerlink" href="#safety-impact" title="Link to this heading">#</a></h2>
<p>The AI Platform is designed to support both QM and ASIL-B use cases, with a clear separation between safety-relevant and non-safety-relevant functionality.</p>
<p>The following list gives an idea of safety considerations and is not complete. An in-depth safety analysis must be conducted in the future.</p>
<ul class="simple">
<li><dl class="simple">
<dt>Inference Backends</dt><dd><ul>
<li><p>For safety-related features (e.g. perception), inference backends must be certified</p></li>
<li><p>The backend abstraction layer must be minimal and deterministic to allow safety analysis and independent certification - it must achieve at least the same ASIL-level as the backends</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Data Pipelines</dt><dd><ul>
<li><p>GPU-based data flows used in safety functions must ensure determinism, bounded latency, and isolation from non-safety components</p></li>
<li><p>Zero-copy paths must ensure safe memory access patterns and partitioning</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>GenAI</dt><dd><ul>
<li><p>GenAI workloads are scoped as QM</p></li>
<li><p>LLM-driven actions must not bypass safety monitoring or certified control paths</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="license-impact">
<h2>License Impact<a class="headerlink" href="#license-impact" title="Link to this heading">#</a></h2>
<p>The AI Platform is expected to be implemented primarily using Free and Open Source Software (FOSS), in alignment with the Eclipse Foundation’s licensing principles.</p>
<ul class="simple">
<li><p>All new components (e.g. abstraction layers, adapters, GenAI interfaces) developed under this feature shall be licensed under the Apache 2.0 License</p></li>
<li><p>Third-party runtime dependencies such as ONNX Runtime or llama.cpp are also licensed under permissive FOSS licenses (MIT, Apache 2.0), making them compatible with the overall platform license</p></li>
<li><p>Any optional use of proprietary or closed-source AI runtimes (e.g. vendor-specific TensorRT libraries) must be isolated behind the backend abstraction and excluded from the FOSS-licensed deliverables</p></li>
</ul>
<p>No additional licensing constraints are introduced by this feature request beyond those already adopted in S-CORE.</p>
</section>
<section id="how-to-teach-this">
<h2>How to Teach This<a class="headerlink" href="#how-to-teach-this" title="Link to this heading">#</a></h2>
<p>The following sources are recommended for onboarding:</p>
<ul class="simple">
<li><p>ONNX Runtime GitHub Repo <a class="footnote-reference brackets" href="#s1" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a></p></li>
<li><p>llama.cpp GitHub Repo <a class="footnote-reference brackets" href="#s2" id="id5" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a></p></li>
<li><p>MCP Servers GitHub Repo <a class="footnote-reference brackets" href="#s3" id="id6" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a></p></li>
</ul>
<p>And of course: Udemy, Youtube, Google, etc.</p>
</section>
<section id="rejected-ideas">
<h2>Rejected Ideas<a class="headerlink" href="#rejected-ideas" title="Link to this heading">#</a></h2>
<p>Dynamic runtime backend selection was rejected to ensure deterministic behavior and reduce runtime complexity, particularly for ASIL-B use cases.
Static backend selection at build time enables better certification and minimizes safety risks.</p>
<p>Direct integration of inference logic into applications without a common abstraction layer was rejected to avoid code duplication, maintain modularity and enable cross-platform backend support.
The adapter-based architecture allows better testability and reuse across QNX and Linux as well has HW platforms.</p>
</section>
<section id="open-issues">
<h2>Open Issues<a class="headerlink" href="#open-issues" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>GPU shared memory data pipeline and tight coupling of GPU memory object to vendor specific libraries</p></li>
<li><p>ONNX support on QNX</p></li>
<li><p>S-CORE recording may not capture GPU-to-GPU data flows</p></li>
<li><p>Agentic support evaluation</p></li>
<li><p>Decide on inference engine for QNX (e.g. ONNX, LiteRT, ExecuTorch)</p></li>
<li><p>Decide on GenAI runtime (e.g. llama.cpp)</p></li>
<li><p>Select language per components (cpp vs rust), e.g. rust for MCP Server</p></li>
</ul>
</section>
<section id="footnotes">
<h2>Footnotes<a class="headerlink" href="#footnotes" title="Link to this heading">#</a></h2>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="s1" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id4">2</a>)</span>
<p>“ONNX Runtime repo”, GitHub Microsoft, <a class="github reference external" href="https://github.com/microsoft/onnxruntime">microsoft/onnxruntime</a>.</p>
</aside>
<aside class="footnote brackets" id="s2" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id2">1</a>,<a role="doc-backlink" href="#id5">2</a>)</span>
<p>“llama.cpp repo”, GitHub ggml-org, <a class="github reference external" href="https://github.com/ggml-org/llama.cpp">ggml-org/llama.cpp</a>.</p>
</aside>
<aside class="footnote brackets" id="s3" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id3">1</a>,<a role="doc-backlink" href="#id6">2</a>)</span>
<p>“MCP Servers repo”, GitHub modelcontextprotocol, <a class="github reference external" href="https://github.com/modelcontextprotocol/servers">modelcontextprotocol/servers</a>.</p>
</aside>
</aside>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Features</p>
      </div>
    </a>
    <a class="right-next"
       href="requirements/index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Requirements</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-flag">Feature flag</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abstract">Abstract</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation">Motivation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rationale">Rationale</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#specification">Specification</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#operating-system-support-and-asil-alignment">Operating System Support and ASIL Alignment</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#qnx">QNX</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#linux">Linux</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-backend-integration-and-abstraction-layer">Inference Backend Integration and Abstraction Layer</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#concept">Concept</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#adapter-class">Adapter Class</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#backend-selection-mechanism">Backend Selection Mechanism</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-pipelining-and-gpu-communication-abstraction">Data Pipelining and GPU Communication Abstraction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#s-core-integration-feo-communication-and-fault-management">S-CORE Integration: FEO, Communication, and Fault Management</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#genai">GenAI</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#scope-overview">Scope Overview</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#runtime">Runtime</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#prompting-interface">Prompting Interface</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#context-api">Context API</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-context-protocol-mcp-client-server">Model Context Protocol (MCP) Client/Server</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#action-validator">Action Validator</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#requirements">Requirements</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#backwards-compatibility">Backwards Compatibility</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#security-impact">Security Impact</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#safety-impact">Safety Impact</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#license-impact">License Impact</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-teach-this">How to Teach This</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rejected-ideas">Rejected Ideas</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-issues">Open Issues</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#footnotes">Footnotes</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  
  <div class="tocsection editthispage">
    <a href="https://github.com/dummy/dummy/edit/main/docs/features/ai_platform/index.rst">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/features/ai_platform/index.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.2.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>